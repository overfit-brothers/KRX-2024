{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infidea/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,Dataset,concatenate_datasets,interleave_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_origin = load_dataset('overfit-brothers/mmmlu_kor_revised_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선택지 순서 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "def augment_dataset(dataset_dict, num_augmentations):\n",
    "    # 새로운 DatasetDict 생성\n",
    "    augmented_dataset = DatasetDict()\n",
    "    \n",
    "    # 각 스플릿에 대해 증강 수행\n",
    "    for split in dataset_dict.keys():\n",
    "        original_data = dataset_dict[split]\n",
    "        augmented_examples = []\n",
    "        \n",
    "        # 각 예제에 대해 증강 수행\n",
    "        for example in original_data:\n",
    "            \n",
    "            # 추가 증강 데이터 생성\n",
    "            for _ in range(num_augmentations):\n",
    "                new_example = deepcopy(example)\n",
    "                \n",
    "                # 현재 정답 찾기\n",
    "                original_question = example['question_original']\n",
    "                original_answer = example['answer']\n",
    "                choices = ['A', 'B', 'C', 'D']\n",
    "                choice_contents = {\n",
    "                    'A': example['A'],\n",
    "                    'B': example['B'],\n",
    "                    'C': example['C'],\n",
    "                    'D': example['D']\n",
    "                }\n",
    "                \n",
    "                # 선택지 순서 섞기 (정답 위치가 바뀔 때까지)\n",
    "                while True:\n",
    "                    new_choices = choices.copy()\n",
    "                    random.shuffle(new_choices)\n",
    "                    if new_choices.index(original_answer) != choices.index(original_answer):\n",
    "                        break\n",
    "                \n",
    "                # 새로운 순서로 선택지 재배치\n",
    "                for i, new_choice in enumerate(new_choices):\n",
    "                    new_example[choices[i]] = choice_contents[new_choice]\n",
    "                    if new_choice == original_answer:\n",
    "                        new_example['answer'] = choices[i]\n",
    "                a,b,c,d = new_example['A'], new_example['B'], new_example['C'], new_example['D']\n",
    "                new_example['question'] =  f'{original_question} ### 선택지: A.{a} B.{b} C.{c} D.{d}'\n",
    "                choices = []\n",
    "                for choice in new_example.keys():\n",
    "                    if choice not in ['question_original', 'answer', 'question']:\n",
    "                        choices.append(new_example[choice])\n",
    "                new_example['choices'] = choices\n",
    "                del new_example['A']\n",
    "                del new_example['B'] \n",
    "                del new_example['C']\n",
    "                del new_example['D']                \n",
    "                augmented_examples.append(new_example)\n",
    "        \n",
    "        # 증강된 데이터로 새로운 Dataset 생성\n",
    "        augmented_dataset[split] = Dataset.from_list(augmented_examples)\n",
    "    \n",
    "    return augmented_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_shuffle = augment_dataset(mmmlu_origin, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까? ### 선택지: A.반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다 B.반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다 C.반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다 D.반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다',\n",
       " 'answer': 'D',\n",
       " 'question_original': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까?',\n",
       " 'choices': ['반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다',\n",
       "  '반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmmlu_shuffle['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까? ### 선택지: A.반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다 B.반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다 C.반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다 D.반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다',\n",
       " 'answer': 'C',\n",
       " 'question_original': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까?',\n",
       " 'A': '반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다',\n",
       " 'B': '반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다',\n",
       " 'C': '반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다',\n",
       " 'D': '반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmmlu_shuffle['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선택지 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "def reduce_choices(dataset_dict):\n",
    "    augmented_dataset = DatasetDict()\n",
    "    \n",
    "    for split in dataset_dict.keys():\n",
    "        original_data = dataset_dict[split]\n",
    "        reduced_examples = []\n",
    "        \n",
    "        for example in original_data:\n",
    "            new_example = deepcopy(example)\n",
    "            original_question = example['question'].split('###')[0].strip()\n",
    "            \n",
    "            # 현재 정답과 선택지들\n",
    "            answer = example['answer']\n",
    "            choices = ['A', 'B', 'C', 'D']\n",
    "            choice_contents = {\n",
    "                'A': example['A'],\n",
    "                'B': example['B'],\n",
    "                'C': example['C'],\n",
    "                'D': example['D']\n",
    "            }\n",
    "            \n",
    "            # 제거할 선택지 개수를 랜덤하게 결정 (1 또는 2)\n",
    "            num_to_remove = random.randint(1, 2)\n",
    "            \n",
    "            # 정답을 제외한 선택지 중에서 랜덤하게 선택하여 제거\n",
    "            removable_choices = [c for c in choices if c != answer]\n",
    "            choices_to_remove = random.sample(removable_choices, num_to_remove)\n",
    "            \n",
    "            # 새로운 선택지 순서 생성\n",
    "            remaining_choices = [c for c in choices if c not in choices_to_remove]\n",
    "            new_choice_contents = {}\n",
    "            new_answer = answer\n",
    "            \n",
    "            # 선택지 재배치\n",
    "            new_choice_labels = ['A', 'B', 'C'][:len(remaining_choices)]\n",
    "            for i, new_choice in enumerate(new_choice_labels):\n",
    "                original_choice = remaining_choices[i]\n",
    "                new_choice_contents[new_choice] = choice_contents[original_choice]\n",
    "                if original_choice == answer:\n",
    "                    new_answer = new_choice\n",
    "            \n",
    "            # 새로운 예제 생성\n",
    "            new_example['answer'] = new_answer\n",
    "            for i, label in enumerate(new_choice_labels):\n",
    "                new_example[label] = new_choice_contents[label]\n",
    "            \n",
    "            # 제거된 선택지들 삭제\n",
    "            for choice in choices[len(remaining_choices):]:\n",
    "                del new_example[choice]\n",
    "            \n",
    "            # question 칼럼 업데이트\n",
    "            choice_text = ' '.join([f\"{label}.{new_choice_contents[label]}\" for label in new_choice_labels])\n",
    "            new_example['question'] = f\"{original_question} ### 선택지: {choice_text}\"\n",
    "            \n",
    "            # None 값을 가진 키 제거\n",
    "            new_example = {k: v for k, v in new_example.items() if v is not None}\n",
    "            choices = []\n",
    "            for choice in new_example.keys():\n",
    "                if choice not in ['question_original', 'answer', 'question']:\n",
    "                    choices.append(new_example[choice])\n",
    "            new_example['choices'] = choices\n",
    "            \n",
    "            for key in ['A', 'B', 'C', 'D']:\n",
    "                if key in new_example:\n",
    "                    del new_example[key]\n",
    "            reduced_examples.append(new_example)\n",
    "        \n",
    "        augmented_dataset[split] = Dataset.from_list(reduced_examples)\n",
    "    \n",
    "    return augmented_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_reduced = reduce_choices(mmmlu_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선택지 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_API_KEY = \"sk-XXX\"\n",
    "import openai\n",
    "client = openai.OpenAI(api_key=GPT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(question, choices, answer, num_augment):\n",
    "    prompt = f\"\"\"\n",
    "    문제와 선택지를 읽고 파악한 후에, 정답이 아닌 추가적인 선택지를 {num_augment}개 만들어 주세요. \n",
    "    \n",
    "    - 요구사항: \n",
    "    1. 주어진 선택지들과 전부 다른 선택지를 만들어야 합니다.\n",
    "    2. 문제와 관련이 있는 선택지를 만들어야 합니다.\n",
    "    3. 정답과는 논리적으로 연관이 없는 선택지를 만들어야 합니다.\n",
    "    4. 알파벳이나 숫자 번호 없이 선택지만 출력해야 합니다.\n",
    "    \n",
    "    문제: {question}\n",
    "    선택지: {choices}\n",
    "    정답: {answer}\n",
    "    \n",
    "    출력 형식(리스트):\n",
    "    [\n",
    "        \"추가적인 선택지 1\",\n",
    "        \"추가적인 선택지 2\",\n",
    "        \"추가적인 선택지 3\",\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    추가 선택지 리스트:\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "class AnswerModel(BaseModel):\n",
    "    answer : List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '(주)한공은 2013년 10월 1일 장기투자를 목적으로 (주)더존의 주식 100주를 주당 1,000원에 취득하였다. (주)더존의 주식은 한국거래소에 상장되어 있으며, 2013년 12월 31일 결산일의 공정가치는 주당 1,300원이다. 공정가치를 반영하기 위한 분개로 옳은 것은? ### 선택지: A.(차) 단기매매증권 : 30,000원, (대) 단기매매증권평가이익 : 30,000원 B.(차) 매도가능증권 : 30,000원, (대) 매도가능증권평가이익 : 30,000원 C.(차) 단기매매증권평가손실 : 30,000원, (대) 단기매매증권 : 30,000원 D.(차)  매도가능증권평가손실 : 30,000원, (대) 매도가능증권 : 30,000원',\n",
       " 'answer': 'B',\n",
       " 'question_original': '(주)한공은 2013년 10월 1일 장기투자를 목적으로 (주)더존의 주식 100주를 주당 1,000원에 취득하였다. (주)더존의 주식은 한국거래소에 상장되어 있으며, 2013년 12월 31일 결산일의 공정가치는 주당 1,300원이다. 공정가치를 반영하기 위한 분개로 옳은 것은?',\n",
       " 'A': '(차) 단기매매증권 : 30,000원, (대) 단기매매증권평가이익 : 30,000원',\n",
       " 'B': '(차) 매도가능증권 : 30,000원, (대) 매도가능증권평가이익 : 30,000원',\n",
       " 'C': '(차) 단기매매증권평가손실 : 30,000원, (대) 단기매매증권 : 30,000원',\n",
       " 'D': '(차)  매도가능증권평가손실 : 30,000원, (대) 매도가능증권 : 30,000원'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmmlu_origin['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "def augment_choices(dataset_dict):\n",
    "    augmented_dataset = DatasetDict()\n",
    "    \n",
    "    for split in dataset_dict.keys():\n",
    "        original_data = dataset_dict[split]\n",
    "        auemented_examples = []\n",
    "        \n",
    "        for example in original_data:\n",
    "            new_example = deepcopy(example)\n",
    "            original_question = example['question_original']\n",
    "            \n",
    "            # 현재 정답과 선택지들\n",
    "            answer = example['answer']\n",
    "            original_choices = ['A', 'B', 'C', 'D']\n",
    "            choice_contents = {\n",
    "                'A': example['A'],\n",
    "                'B': example['B'],\n",
    "                'C': example['C'],\n",
    "                'D': example['D']\n",
    "            }\n",
    "            \n",
    "            num_to_augment = random.randint(1, 3)\n",
    "            prompt = make_prompt(original_question, str(choice_contents), answer, num_to_augment)\n",
    "            response = client.beta.chat.completions.parse(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                response_format=AnswerModel\n",
    "            )\n",
    "            answer_list = eval(response.choices[0].message.content)['answer']\n",
    "            \n",
    "            # Add new choices in alphabetical order\n",
    "            maked_choices = ['E', 'F', 'G'][:num_to_augment]\n",
    "            for maked_choice, new_content in zip(maked_choices, answer_list):\n",
    "                new_example[maked_choice] = new_content            \n",
    "            \n",
    "            # Shuffle all choices\n",
    "            all_choices = original_choices + maked_choices\n",
    "            choice_mapping = {}\n",
    "            shuffled_contents = []\n",
    "            \n",
    "            # Create list of all contents\n",
    "            for choice in all_choices:\n",
    "                shuffled_contents.append(new_example[choice])\n",
    "                if choice == answer:\n",
    "                    original_answer_content = new_example[choice]\n",
    "            \n",
    "            # Shuffle contents\n",
    "            random.shuffle(shuffled_contents)\n",
    "            \n",
    "            # Reassign shuffled contents and track new answer position\n",
    "            for i, choice in enumerate(all_choices):\n",
    "                new_example[choice] = shuffled_contents[i]\n",
    "                if shuffled_contents[i] == original_answer_content:\n",
    "                    new_example['answer'] = choice\n",
    "                    \n",
    "            full_choices = original_choices+maked_choices\n",
    "            # question 칼럼 업데이트\n",
    "            choice_text = ' '.join([f\"{label}.{new_example[label]}\" for label in full_choices])\n",
    "            new_example['question'] = f\"{original_question} ### 선택지: {choice_text}\"\n",
    "            \n",
    "            choices = []\n",
    "            for choice in new_example.keys():\n",
    "                if choice not in ['question_original', 'answer', 'question']:\n",
    "                    choices.append(new_example[choice])\n",
    "            new_example['choices'] = choices\n",
    "            \n",
    "            for key in ['A', 'B', 'C', 'D','E', 'F', 'G']:\n",
    "                if key in new_example:\n",
    "                    del new_example[key]\n",
    "            auemented_examples.append(new_example)\n",
    "        augmented_dataset[split] = Dataset.from_list(auemented_examples)\n",
    "    return augmented_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_augmented = augment_choices(mmmlu_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까? ### 선택지: A.반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다 B.반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다 C.반복적인 표본에서 99%의 경우 통계량이 항상 같은 값을 가질 것입니다 D.반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다 E.반복적인 표본에서 99%의 경우 구간의 길이가 일정하게 유지될 것입니다 F.반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다',\n",
       " 'answer': 'D',\n",
       " 'question_original': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까?',\n",
       " 'choices': ['반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 통계량이 항상 같은 값을 가질 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다',\n",
       "  '반복적인 표본에서 99%의 경우 구간의 길이가 일정하게 유지될 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmmlu_augmented['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(example):\n",
    "    choices = [\n",
    "        example['A'],\n",
    "        example['B'], \n",
    "        example['C'],\n",
    "        example['D']\n",
    "    ]\n",
    "    \n",
    "    # 기존 A,B,C,D 키 제거\n",
    "    del example['A']\n",
    "    del example['B']\n",
    "    del example['C'] \n",
    "    del example['D']\n",
    "    \n",
    "    # choices 칼럼 추가\n",
    "    example['choices'] = choices\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 379/379 [00:00<00:00, 9930.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "kmmlu_origin['train'] = kmmlu_origin['train'].map(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmlu_origin['train'] = mmmlu_origin['train'].map(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_full = concatenate_datasets([mmmlu_origin['train'],mmmlu_shuffle['train'], mmmlu_reduced['train'],mmmlu_augmented['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까? ### 선택지: A.반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다 B.반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다 C.반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다 D.반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다',\n",
       " 'answer': 'A',\n",
       " 'question_original': '다음 중 99% 신뢰구간을 가장 적절하게 정의한 것은 무엇입니까?',\n",
       " 'choices': ['반복적인 표본에서 99%의 경우 그 구간에는 모수의 실제 값이 포함될 수 있습니다',\n",
       "  '반복적인 표본에서 99%의 경우 그 구간에는 모수의 추정 값이 포함될 수 있습니다',\n",
       "  '반복적인 표본에서 99%의 경우 귀무 가설이 기각될 것입니다',\n",
       "  '반복적인 표본에서 99%의 경우 귀무 가설이 거짓일 때 해당 가설이 기각되지 않을 것입니다']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmmlu_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'GDP는  ### 선택지: A.국가 국경 내에서 생산되는 것이다. B.국가의 문화적 영향을 반영한 경제 지표이다. C.해외에서 수입되는 모든 상품의 가치이다. D.생산 요소로 벌어들인 소득에 감가상각비 및 간접 사업세를 더한 금액이다. E.한 국가의 국민이 어디에 있든 생산할 수 있는 것이다. F.(A) 및 (C)',\n",
       " 'answer': 'F',\n",
       " 'question_original': 'GDP는 ',\n",
       " 'A': '국가 국경 내에서 생산되는 것이다.',\n",
       " 'B': '국가의 문화적 영향을 반영한 경제 지표이다.',\n",
       " 'C': '해외에서 수입되는 모든 상품의 가치이다.',\n",
       " 'D': '생산 요소로 벌어들인 소득에 감가상각비 및 간접 사업세를 더한 금액이다.',\n",
       " 'E': '한 국가의 국민이 어디에 있든 생산할 수 있는 것이다.'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmmlu_augmented['train'][121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mmmlu_full.push_to_hub('overfit-brothers/mmmlu_revised_augmented',private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 풀이 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_API_KEY = \"sk-XXX\"\n",
    "import openai\n",
    "client = openai.OpenAI(api_key=GPT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cot_prompt(question):\n",
    "    prompt = f\"\"\"\n",
    "    문제를 읽고 파악한 후에, 풀이과정과 정답을 알려주세요. \n",
    "    \n",
    "    - 요구사항: \n",
    "    1. 문제를 읽고 파악하고 문제에서 요구하는 목표를 간략하게 1문장으로 말하세요.\n",
    "    2. 풀이과정은 논리적 사고 흐름에 따라 생각의 사슬 형식으로 설명하세요. \n",
    "    3. 도출된 답안을 제시하고 마지막에 다음과 같이 정답의 기호를 한번 더 언급해 주세요. ### 정답: [정답 기호]\n",
    "    \n",
    "    답변 형식:\n",
    "    1) 문제 분석: [문제의 핵심 내용 정리]\n",
    "    2) 풀이 과정: [단계별 설명,문장 형식]\n",
    "    3) 최종 정답: ### 정답: [정답 기호]\n",
    "    \n",
    "    문제: \n",
    "    {question}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "\n",
    "mmmlu = load_dataset(\"overfit-brothers/mmmlu_revised_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'XXX'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'XXX'\n",
    "def make_cot(example):\n",
    "    # bedrock_runtime = boto3.client(\n",
    "    #     service_name='bedrock-runtime',\n",
    "    #     region_name='us-east-1'\n",
    "    # )\n",
    "    res_list = []\n",
    "    total_count = len(example)\n",
    "    answer_count = 0\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "    for datum in tqdm(example):\n",
    "        question = datum['question']\n",
    "        answer = datum['answer']\n",
    "        prompt = make_cot_prompt(question)\n",
    "        # body = json.dumps({\n",
    "        # \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        # \"max_tokens\": 1000,\n",
    "        # \"messages\": [\n",
    "        #     {\n",
    "        #         \"role\": \"user\",\n",
    "        #         \"content\": prompt\n",
    "        #             }\n",
    "        #         ]\n",
    "        #     })\n",
    "        # # Claude API 호출\n",
    "        # response = bedrock_runtime.invoke_model(\n",
    "        #     modelId='us.anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
    "        #     body=body\n",
    "        # )\n",
    "        \n",
    "        # 응답 파싱\n",
    "        # response_body = json.loads(response.get('body').read())\n",
    "        # response_text = response_body['content'][0]['text']\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        input_tokens += response.usage.prompt_tokens\n",
    "        output_tokens += response.usage.completion_tokens\n",
    "        response_text = response.choices[0].message.content\n",
    "        response_answer = max(['A','B','C','D','E','F','G'], key=lambda x: response_text.count(x))\n",
    "        if answer == response_answer:\n",
    "            answer_count += 1\n",
    "            datum['answer'] = response_text\n",
    "            res_list.append(datum)\n",
    "        else:\n",
    "            continue\n",
    "    res_dataset = Dataset.from_list(res_list)\n",
    "    print(f'{answer_count}/{total_count} {answer_count/total_count*100:.2f}%')\n",
    "    print(f'Input tokens: {input_tokens} (${input_tokens * 2.5 / 1000000:.4f})')\n",
    "    print(f'Output tokens: {output_tokens} (${output_tokens * 10.0 / 1000000:.4f})')\n",
    "    return res_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmlu_cot = make_cot(mmmlu['train'])\n",
    "mmmlu_cot.push_to_hub('overfit-brothers/mmmlu_revised_augmented_cot',private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
